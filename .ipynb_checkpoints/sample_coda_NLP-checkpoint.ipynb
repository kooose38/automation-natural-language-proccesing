{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kooose38/automation-natural-language-proccesing/blob/dev/sample_coda_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE8SnHVN4p39"
   },
   "source": [
    "ここでは`code/`に構成されているファイルの使用方法についてのサンプルコードを記載します。主に自然言語処理の生データへの前処理を中心としたツールの紹介です。細かい処理には向きませんが、非常に短いコードで実行できます。  \n",
    "\n",
    "まずは、大まかなファイルの役割について言及します。\n",
    "```\n",
    ".\n",
    "├── SeqTransformToVector.py  -- 文章に対してのベクトル処理\n",
    "├── WordTransformToVector.py -- 単語に対してのベクトル処理\n",
    "├── mecab-ipadic-neologd --\n",
    "├── morphological.py -- 形態素解析を行うクラス \n",
    "├── orgment\n",
    "│   └── googleTranslation.py -- Google翻訳を使った文章生成\n",
    "└── request.py -- データの取得  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IkEcIi1m3jLz",
    "outputId": "ffe0f06e-3ea7-4eff-dbd2-e498338a5c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Github\n",
      "/content/drive/My Drive/Github/automation-natural-language-proccesing/code\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/Github/\n",
    "!git clone https://github.com/kooose38/automation-natural-language-proccesing\n",
    "%cd ./automation-natural-language-proccesing/code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbT_sXH-443A"
   },
   "source": [
    "必要なパッケージをインストールします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZChjlzr8m1B",
    "outputId": "069a738c-cab9-49a9-c68d-0411cf796099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\t\t  orgment     SeqTransformToVector.py\n",
      "morphological.py  request.py  WordTransformToVector.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQtiwjIV89Zl",
    "outputId": "3a173f5b-8ab3-4965-b34c-e4c87cee431b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 378 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt update -y\n",
    "apt install -y autoconf automake build-essential libtool python-dev\n",
    "apt install jq  # コマンドライン\n",
    "pip install jq=0.1.8\n",
    "# Wikipedia API へアクセスして、取得した内容(JSON形式のデータ)を `wikipedia.json` に保存\n",
    "curl -sS -XPOST \\\n",
    "    \"https://ja.wikipedia.org/w/api.php?format=json&action=query&prop=extracts&exlimit=1\" \\\n",
    "    --data-urlencode \"titles=自然言語\" -o wikipedia.json\n",
    "\n",
    "# 保存した内容(JSON形式)を整形して表示\n",
    "cat wikipedia.json | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2DmPzLp66gg"
   },
   "source": [
    "### 1. `request.py`への理解\n",
    "主に、**html**,**zip**,**json**からの読み込みが自動で実行できる役割を持っています。追加で取得されたテキストを行で分割してから、**クレンジング処理**を行います。なおクレンジングには[青空文庫データセット](http://aozora-word.hahasoha.net)を参考にしたものになるので、必要に応じてコードを改変します。`re`による正規表現を使うと容易にクレンジングを行うことが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IoRMJbJi638G"
   },
   "outputs": [],
   "source": [
    "from request import LoadDataset\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kljBj4Mt64GO"
   },
   "outputs": [],
   "source": [
    "zip_url = \"http://www.aozora.gr.jp/cards/000083/files/1368_ruby_36901.zip\"\n",
    "html_url = \"http://www.aozora.gr.jp/cards/000083/files/1368_37258.html\"\n",
    "\n",
    "dataloader = LoadDataset() # クラスのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnBO2mKO-SjX",
    "outputId": "613dd56a-6f4b-401d-9d13-dd62fb97dad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['天下大乱の兆',\n",
      " '応仁の大乱は応仁元年より、文明九年まで続いた十一年間の事変である。戦争としては、何等目を驚かすものがあるわけでない。勇壮な場面や、華々しい情景には乏しい。活躍する人物にも英雄豪傑はいない。それが十一年もだらだらと続いた、緩慢な戦乱である。',\n",
      " '併しだらだらでも十一年続いたから、その影響は大きい。京都に起った此の争乱がやがて、地方に波及拡大し、日本国中が一つの軟体動物の蠕動運動の様に、動揺したのである。此の後に来るものが所謂戦国時代だ。即ち実力主義が最も露骨に発揮された、活気横溢せる時代である。武士にとっては滅多に願ってもかなえられない得意の時代が来たのだ。心行くまで彼等に腕を振わせる大舞台が開展したのだ。その意味で序幕の応仁の乱も、意義があると云うべきである。']\n"
     ]
    }
   ],
   "source": [
    "sample_text_from_zip = dataloader.load_zip(zip_url)\n",
    "pprint(sample_text_from_zip[:3]) # 行単位でリスト化されて返ります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mXt-RM7_Cyi",
    "outputId": "42b0d27d-2e3a-48ba-cae0-924df1921060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['菊池寛 応仁の乱',\n",
      " '応仁の乱',\n",
      " '菊池寛',\n",
      " '天下大乱の兆',\n",
      " '応仁の大乱は応仁元年より、文明九年まで続いた十一年間の事変である。戦争としては、何等目を驚かすものがあるわけでない。勇壮な場面や、華々しい情景には乏しい。活躍する人物にも英雄豪傑はいない。それが十一年もだらだらと続いた、緩慢な戦乱である。',\n",
      " '併しだらだらでも十一年続いたから、その影響は大きい。京都に起った此の争乱がやがて、地方に波及拡大し、日本国中が一つの軟体動物の蠕動（ぜんどう）運動の様に、動揺したのである。此の後に来（きた）るものが所謂（いわゆる）戦国時代だ。即ち実力主義が最も露骨に発揮された、活気横溢せる時代である。武士にとっては滅多に願ってもかなえられない得意の時代が来たのだ。心行くまで彼等に腕を振わせる大舞台が開展したのだ。その意味で序幕の応仁の乱も、意義があると云うべきである。',\n",
      " '応仁の乱の責任者として、古来最も指弾されて居るのは、将軍義政で、秕政（ひせい）と驕奢（きょうしゃ）が、その起因をなしたと云われる。',\n",
      " '義満の金閣寺に真似て、銀閣を東山に建てたが、費用が足りなくて銀が箔（は）れなかったなど、有名な話である。大体彼は建築道楽で、寛正（かんしょう）の大飢饉に際し、死屍（しし）京の賀茂川を埋むる程なのに、新邸の造営に余念がない。',\n",
      " '彼の豪奢の絶頂は、寛正六年三月の花頂山の花見宴であろう。咲き誇る桜の下で当時流行の連歌会を催し、義政自ら発句を作って、',\n",
      " '「咲き満ちて、花より外に色もなし」と詠じた。一代の享楽児の面目躍如たるものがある。併し義政は単に一介の風流人ではなく、相当頭のよい男であった。天下大乱の兆、漸（ようや）くきざし、山名細川両氏の軋轢（あつれき）甚しく、両氏は互いに義政を利用しようとして居る。ところが彼は巧みに両氏の間を泳いで不即不離の態度をとって居る。だから両軍から別に憎怨（ぞうおん）せられず、戦乱に超越して風流を楽んで居られたのである。政治的陰謀の激しい下剋上（げこくじょう）の当時に於て、暗殺されなかっただけでも相当なものだ。尤もそれだけに政治家としては、有っても無くてもよい存在であったのかも知れぬ。']\n"
     ]
    }
   ],
   "source": [
    "sample_text_from_html = dataloader.load_html(html_url)\n",
    "pprint(sample_text_from_html[:10]) # html.xpath(\"//div[@class=\"main\"]\")でタグ指定で取り出す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2F5tS87Aj1m"
   },
   "source": [
    "最後に**json**の読み込みです。webからの読み込みには多くの場合でhtmlタグが含まれるので除去を共通化しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "powPySp-AG3P",
    "outputId": "75584540-89bc-4428-9dcb-8f004d47186e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"batchcomplete\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"warnings\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"extracts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"*\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"HTML may be malformed and/or unbalanced and may omit inline images. Use at your own risk. Known problems are listed at https://www.mediawiki.org/wiki/Special:MyLanguage/Extension:TextExtracts#Caveats.\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"query\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"pages\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"68\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"pageid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m68\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"ns\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"自然言語\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"extract\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"<p><b>自然言語</b>（しぜんげんご、英: <span lang=\\\"en\\\">natural language</span>）とは、言語学や論理学、計算機科学の専門用語で、「英語」・「中国語」・「日本語」といった「○○語」の総称。つまり普通の「言語」のこと。人間が意思疎通のために日常的に用いる言語であり、文化的背景を持っておのずから発展してきた言語。\\n</p><p>対義語は「人工言語」「形式言語」、すなわちプログラミング言語や論理式など。\\n</p>\\n<h2><span id=\\\".E6.A6.82.E8.A6.81\\\"></span><span id=\\\"概要\\\">概要</span></h2>\\n<p>人間がお互いにコミュニケーションを行うための自然発生的な言語である。形式言語との対比では、その構文や意味が明確に揺るぎなく定められ利用者に厳格な規則の遵守を強いる（ことが多い）形式言語に対し、話者集団の社会的文脈に沿った曖昧な規則が存在していると考えられるものが自然言語である。自然言語には、規則が曖昧であるがゆえに、話者による規則の解釈の自由度が残されており、話者が直面した状況に応じて規則の解釈を変化させることで、状況を共有する他の話者とのコミュニケーションを継続する事が可能となっている。\\n</p><p>人間のコミュニケーションを目的として設計された形式言語、といったようなものも存在するが（ログランなど）あまり多くない。人工言語という分類は多義的であり、形式言語のことを指している場合もあれば、エスペラントなど「人為発生的な自然言語」といったほうが良い場合もある。\\n</p><p>また、文法,単語の用法に曖昧さを含み、使用する単語,単語の順序を入れ替える等が可能であり、感情で文章を制御しやすいため、多様な情景表現が可能となっている。しかし、文法、単語の用法が曖昧であるため、「言語仕様」のように明確に固定することは難しい。各自然言語自体も他言語との統合が起きる事により変化し続けており、自然言語の文法その他あらゆる面が言語学によって研究が続けられている。また、統計的手法を利用する<span title=\\\"リンク先の項目はまだ不十分なため、加筆や他言語版からの追加翻訳が望まれます。\\\">計量言語学</span>や、情報処理の対象として自然言語を扱う自然言語処理は、コンピュータの能力の向上にあわせ、またコンピュータのより便利な利用のために（例えばワードプロセッサや、音声入力による情報探索など）、さかんに研究され実地にも応用されるようになった。\\n</p>\\n<h2><span id=\\\".E6.B3.A8\\\"></span><span id=\\\"注\\\">注</span></h2>\\n\\n<h2><span id=\\\".E9.96.A2.E9.80.A3.E9.A0.85.E7.9B.AE\\\"></span><span id=\\\"関連項目\\\">関連項目</span></h2>\\n<ul><li>自然言語処理</li>\\n<li>曖昧</li>\\n<li>文脈</li>\\n<li>修辞技法</li>\\n<li>モンタギュー文法</li>\\n<li>生成文法</li>\\n<li>依存文法</li>\\n<li>構文解析</li>\\n<li>形式文法</li>\\n<li>句構造規則</li>\\n<li>日常言語学派</li>\\n<li>認知言語学</li></ul>\\n<!-- \\nNewPP limit report\\nParsed by mw2400\\nCached time: 20210725181918\\nCache expiry: 1814400\\nReduced expiry: false\\nComplications: []\\nCPU time usage: 0.137 seconds\\nReal time usage: 0.184 seconds\\nPreprocessor visited node count: 580/1000000\\nPost‐expand include size: 13458/2097152 bytes\\nTemplate argument size: 990/2097152 bytes\\nHighest expansion depth: 22/40\\nExpensive parser function count: 2/500\\nUnstrip recursion depth: 0/20\\nUnstrip post‐expand size: 2/5000000 bytes\\nLua time usage: 0.060/10.000 seconds\\nLua memory usage: 2050798/52428800 bytes\\nNumber of Wikibase entities loaded: 1/400\\n-->\\n<!--\\nTransclusion expansion time report (%,ms,calls,template)\\n100.00%  165.764      1 -total\\n 58.60%   97.145      1 Template:出典の明記\\n 46.95%   77.831      1 Template:Ambox\\n 27.25%   45.167      1 Template:Normdaten\\n 22.22%   36.832      1 Template:Find_sources_mainspace\\n 10.05%   16.652      1 Template:DMC\\n  7.86%   13.022      1 Template:DMC/core\\n  5.58%    9.254      1 Template:仮リンク\\n  4.88%    8.092      2 Template:出典の明記/dateHandler\\n  3.79%    6.284      1 Template:Lang-en-short\\n-->\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cat wikipedia.json | jq . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4scTtbFBy_f",
    "outputId": "f4b08e0c-3c2d-49df-f8d3-4b2c5b56d3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<p><b>自然言語</b>（しぜんげんご、英: <span lang=\\\"en\\\">natural language</span>）とは、言語学や論理学、計算機科学の専門用語で、「英語」・「中国語」・「日本語」といった「○○語」の総称。つまり普通の「言語」のこと。人間が意思疎通のために日常的に用いる言語であり、文化的背景を持っておのずから発展してきた言語。\\n</p><p>対義語は「人工言語」「形式言語」、すなわちプログラミング言語や論理式など。\\n</p>\\n<h2><span id=\\\".E6.A6.82.E8.A6.81\\\"></span><span id=\\\"概要\\\">概要</span></h2>\\n<p>人間がお互いにコミュニケーションを行うための自然発生的な言語である。形式言語との対比では、その構文や意味が明確に揺るぎなく定められ利用者に厳格な規則の遵守を強いる（ことが多い）形式言語に対し、話者集団の社会的文脈に沿った曖昧な規則が存在していると考えられるものが自然言語である。自然言語には、規則が曖昧であるがゆえに、話者による規則の解釈の自由度が残されており、話者が直面した状況に応じて規則の解釈を変化させることで、状況を共有する他の話者とのコミュニケーションを継続する事が可能となっている。\\n</p><p>人間のコミュニケーションを目的として設計された形式言語、といったようなものも存在するが（ログランなど）あまり多くない。人工言語という分類は多義的であり、形式言語のことを指している場合もあれば、エスペラントなど「人為発生的な自然言語」といったほうが良い場合もある。\\n</p><p>また、文法,単語の用法に曖昧さを含み、使用する単語,単語の順序を入れ替える等が可能であり、感情で文章を制御しやすいため、多様な情景表現が可能となっている。しかし、文法、単語の用法が曖昧であるため、「言語仕様」のように明確に固定することは難しい。各自然言語自体も他言語との統合が起きる事により変化し続けており、自然言語の文法その他あらゆる面が言語学によって研究が続けられている。また、統計的手法を利用する<span title=\\\"リンク先の項目はまだ不十分なため、加筆や他言語版からの追加翻訳が望まれます。\\\">計量言語学</span>や、情報処理の対象として自然言語を扱う自然言語処理は、コンピュータの能力の向上にあわせ、またコンピュータのより便利な利用のために（例えばワードプロセッサや、音声入力による情報探索など）、さかんに研究され実地にも応用されるようになった。\\n</p>\\n<h2><span id=\\\".E6.B3.A8\\\"></span><span id=\\\"注\\\">注</span></h2>\\n\\n<h2><span id=\\\".E9.96.A2.E9.80.A3.E9.A0.85.E7.9B.AE\\\"></span><span id=\\\"関連項目\\\">関連項目</span></h2>\\n<ul><li>自然言語処理</li>\\n<li>曖昧</li>\\n<li>文脈</li>\\n<li>修辞技法</li>\\n<li>モンタギュー文法</li>\\n<li>生成文法</li>\\n<li>依存文法</li>\\n<li>構文解析</li>\\n<li>形式文法</li>\\n<li>句構造規則</li>\\n<li>日常言語学派</li>\\n<li>認知言語学</li></ul>\\n<!-- \\nNewPP limit report\\nParsed by mw2400\\nCached time: 20210725181918\\nCache expiry: 1814400\\nReduced expiry: false\\nComplications: []\\nCPU time usage: 0.137 seconds\\nReal time usage: 0.184 seconds\\nPreprocessor visited node count: 580/1000000\\nPost‐expand include size: 13458/2097152 bytes\\nTemplate argument size: 990/2097152 bytes\\nHighest expansion depth: 22/40\\nExpensive parser function count: 2/500\\nUnstrip recursion depth: 0/20\\nUnstrip post‐expand size: 2/5000000 bytes\\nLua time usage: 0.060/10.000 seconds\\nLua memory usage: 2050798/52428800 bytes\\nNumber of Wikibase entities loaded: 1/400\\n-->\\n<!--\\nTransclusion expansion time report (%,ms,calls,template)\\n100.00%  165.764      1 -total\\n 58.60%   97.145      1 Template:出典の明記\\n 46.95%   77.831      1 Template:Ambox\\n 27.25%   45.167      1 Template:Normdaten\\n 22.22%   36.832      1 Template:Find_sources_mainspace\\n 10.05%   16.652      1 Template:DMC\\n  7.86%   13.022      1 Template:DMC/core\\n  5.58%    9.254      1 Template:仮リンク\\n  4.88%    8.092      2 Template:出典の明記/dateHandler\\n  3.79%    6.284      1 Template:Lang-en-short\\n-->\"\n",
      "['\"自然言語（しぜんげんご、英:language）とは、言語学や論理学、計算機科学の専門用語で、「英語」・「中国語」・「日本語」といった「○○語」の総称。つまり普通の「言語」のこと。人間が意思疎通のために日常的に用いる言語であり、文化的背景を持っておのずから発展してきた言語。',\n",
      " '対義語は「人工言語」「形式言語」、すなわちプログラミング言語や論理式など。',\n",
      " '概要']\n"
     ]
    }
   ],
   "source": [
    "sample_text_from_json = dataloader.load_json(\"wikipedia.json\")\n",
    "pprint(sample_text_from_json[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0XPz1NwCUzf"
   },
   "source": [
    "ここでのクラスで定義していませんが*table*, *excel*に対しては[Pandas](https://pandas.pydata.org/docs/)により簡単に読み込めるので役割を作っていません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEZ27sVJDZho"
   },
   "source": [
    "### 2. `morphological.py`への理解\n",
    "ここでの処理は形態素を中心とした文章からトークンの作成を行います。手法としては、*mecab*, *janome*, *nagisa*を自動化します。  \n",
    "入力には、以下の形式になります。汎用的に寄せた形となります。\n",
    "```\n",
    "  [[\"1行\", \"1行\" ...],  -- 一文章で構成\n",
    "   [\"1行\", \"1行\" ...],\n",
    "   [\"1行\", \"1行\" ...]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCbrfbPkCFLW"
   },
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install libmecab-dev mecab mecab-ipadic-utf8 mecab-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEfY78cyEFbW"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# NEologd 辞書をインストール\n",
    "\n",
    "## 開始時刻を表示\n",
    "date\n",
    "\n",
    "## 古い辞書があれば削除\n",
    "rm -rf mecab-ipadic-neologd\n",
    "\n",
    "## 辞書のgit リポジトリをclone\n",
    "git clone https://github.com/neologd/mecab-ipadic-neologd.git\n",
    "ls\n",
    "\n",
    "## 辞書をインストール\n",
    "cd mecab-ipadic-neologd && bin/install-mecab-ipadic-neologd -n -a -y\n",
    "\n",
    "## [issue](https://github.com/SamuraiT/mecab-python3#common-issues) への対応\n",
    "pip install unidic-lite\n",
    "\n",
    "pip install -q mecab-python3\n",
    "rm -rf mecab-ipadic-neologd\n",
    "pip install -q janome \n",
    "pip install nagisa \n",
    "\n",
    "## 修了時刻を表示\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_2DyycyFxT0"
   },
   "source": [
    "サンプルデータを使いたいのでデータの形式を変更しています。ここでの処理は必要ありません。  \n",
    "以上から、実行までを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7p7ZyVXiFe0n",
    "outputId": "3d0df4f0-79cf-49e0-a782-716f29ab647e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['菊池寛 応仁の乱', '応仁の乱', '菊池寛', '天下大乱の兆', '応仁の大乱は応仁元年より、文明九年まで続いた十一年間の事変である。戦争としては、何等目を驚かすものがあるわけでない。勇壮な場面や、華々しい情景には乏しい。活躍する人物にも英雄豪傑はいない。それが十一年もだらだらと続いた、緩慢な戦乱である。', '併しだらだらでも十一年続いたから、その影響は大きい。京都に起った此の争乱がやがて、地方に波及拡大し、日本国中が一つの軟体動物の蠕動（ぜんどう）運動の様に、動揺したのである。此の後に来（きた）るものが所謂（いわゆる）戦国時代だ。即ち実力主義が最も露骨に発揮された、活気横溢せる時代である。武士にとっては滅多に願ってもかなえられない得意の時代が来たのだ。心行くまで彼等に腕を振わせる大舞台が開展したのだ。その意味で序幕の応仁の乱も、意義があると云うべきである。', '応仁の乱の責任者として、古来最も指弾されて居るのは、将軍義政で、秕政（ひせい）と驕奢（きょうしゃ）が、その起因をなしたと云われる。', '義満の金閣寺に真似て、銀閣を東山に建てたが、費用が足りなくて銀が箔（は）れなかったなど、有名な話である。大体彼は建築道楽で、寛正（かんしょう）の大飢饉に際し、死屍（しし）京の賀茂川を埋むる程なのに、新邸の造営に余念がない。', '彼の豪奢の絶頂は、寛正六年三月の花頂山の花見宴であろう。咲き誇る桜の下で当時流行の連歌会を催し、義政自ら発句を作って、', '「咲き満ちて、花より外に色もなし」と詠じた。一代の享楽児の面目躍如たるものがある。併し義政は単に一介の風流人ではなく、相当頭のよい男であった。天下大乱の兆、漸（ようや）くきざし、山名細川両氏の軋轢（あつれき）甚しく、両氏は互いに義政を利用しようとして居る。ところが彼は巧みに両氏の間を泳いで不即不離の態度をとって居る。だから両軍から別に憎怨（ぞうおん）せられず、戦乱に超越して風流を楽んで居られたのである。政治的陰謀の激しい下剋上（げこくじょう）の当時に於て、暗殺されなかっただけでも相当なものだ。尤もそれだけに政治家としては、有っても無くてもよい存在であったのかも知れぬ。', '事実、将軍としての彼は、無能であったらしく、治蹟の見る可きものなく、寵嬖（ちょうへき）政治に堕して居る。併し何と云われても、信頼する事の出来ない重臣に取捲かれて居るより、愛妾寵臣の側に居た方が快適であるし、亦（また）安全であるに違いない。殷鑒（いんかん）遠からず、現に嘉吉元年将軍義教（よしのり）は、重臣赤松満祐（みつすけ）に弑（しい）されて居るのである。'], ['亦飢饉時の普請にしても、当時後花園天皇の御諷諫（ごふうかん）に会うや、直（ただ）ちに中止して居る。これなどは、彼の育ちのよいお坊っちゃんらしさが、よく現れて居て、そんなにむきになって批難するにはあたらないと思う。', '所詮彼は一箇の文化人である。近世に於ける趣味生活のよき紹介者であり、学芸の優れた保護者である。義満以来の足利氏の芸術的素質を、最もよく相続して居る。天下既に乱れ身辺に内戚の憂（うれい）多い彼が、纔（わずか）に逃避した境地がその風流である。特に晩年の放縦と驕奢には、政治家として落第であった彼の、ニヒリズムが暗澹（あんたん）たる影を投げて居る。', '故に表面的な驕奢と秕政の故に、義政を以て応仁の乱の責任者であると断ずるは、あたらない。彼は寧（むし）ろ生（うま）る可き時を誤った人間である。借金棒引きを迫って、一揆の頻発した時代だ。天下既に大変革を待って居たのである。', '徳政は元来仁政に発する一種の社会政策である。即ち貝を吹き鐘を敲（たた）いて、徳政の令一度発せられるや、貸借はその瞬間に消滅するのであった。', '増大する窮民はその一揆の口実に徳政を称（とな）え、亦奢侈の結果負債に窮した幕吏も、此の点に於て相応じたのである。義政の時代には、十三度も徳政令を出して居る。', '「九月二十一日、就中（なかんずく）土一揆乱二入京中一（きょうちゅうにらんにゅうす）。而（しかして）土蔵其他家々に令乱入（らんにゅうして）、雑物（ぞうもつ）取る。剰放二火三千余町一焼失（あまつさえさんぜんよちょうにほうかしてしょうしつす）」（『大乗院寺社雑事記』）', '加るに鎮圧に赴いた将士の部下が、却って一揆に参加して諸処に強奪を働いたと云う。', 'その乱脈思う可きである。', '亦当時は博奕（ばくち）が非常に盛んであった。']]\n"
     ]
    }
   ],
   "source": [
    "sentence1, sentence2 = [], [] # 文章を疑似的に分割します\n",
    "sentence = []\n",
    "for i, text in enumerate(dataloader.load_html(html_url)[:20]):\n",
    "  if i <= 10:\n",
    "    sentence1.append(text)\n",
    "  else:\n",
    "    sentence2.append(text)\n",
    "sentence.append(sentence1)\n",
    "sentence.append(sentence2)\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ByVzWv86G-Ju"
   },
   "outputs": [],
   "source": [
    "from morphological import JpTokenizerJanome, JpTokenizerNagisa\n",
    "\n",
    "tokenizer_janome = JpTokenizerJanome()\n",
    "tokenizer_nagisa = JpTokenizerNagisa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMrXNJsDHkZk",
    "outputId": "fb988e7e-1c7e-4915-d10e-c5ae2bbe4af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"janome: ['菊池', '寛', '応仁', '乱', '応仁', '乱', '菊池', '寛', '天下', '大乱']\"\n",
      "\"nagisa: ['菊池', '寛', '\\\\u3000', '応仁', '乱', '応仁', '乱', '菊池', '寛', '天下']\"\n"
     ]
    }
   ],
   "source": [
    "token_janome = tokenizer_janome.transform(sentence)\n",
    "pprint(f\"janome: {token_janome[0][:10]}\")\n",
    "\n",
    "token_nagisa = tokenizer_nagisa.transform(sentence)\n",
    "pprint(f\"nagisa: {token_nagisa[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SWh5qDEKRJV"
   },
   "source": [
    "数行で実行できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JHwy0pDK1iy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "### 3. `WordTransformToVector.py`への理解\n",
    "ここからは作成したトークンから、ベクトルの変換を行っていきます。\n",
    "単語単位でベクトル化するには代表的な手法として以下の２つを取り上げました。\n",
    "+ **One-hot encoder**\n",
    "+ **word2vec**  \n",
    "\n",
    "\n",
    "他にも*fastText*, *ELMO*も有名ですがここでは取り上げていません。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7UNYZuxrJVkY"
   },
   "outputs": [],
   "source": [
    "from WordTransformToVector import OneHotEncoder_, Word2Vec_\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "iUhvEveGMXu_",
    "outputId": "c813aaa7-c81d-4fe1-f114-9ceab79cc8d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>)、</th>\n",
       "      <th>)。</th>\n",
       "      <th>)」(『</th>\n",
       "      <th>あたら</th>\n",
       "      <th>あつ</th>\n",
       "      <th>あまつさえ</th>\n",
       "      <th>ある</th>\n",
       "      <th>あんた</th>\n",
       "      <th>い</th>\n",
       "      <th>いわゆる</th>\n",
       "      <th>いんか</th>\n",
       "      <th>うま</th>\n",
       "      <th>うれ</th>\n",
       "      <th>え</th>\n",
       "      <th>お</th>\n",
       "      <th>おん</th>\n",
       "      <th>かなえ</th>\n",
       "      <th>かんしょ</th>\n",
       "      <th>き</th>\n",
       "      <th>きもの</th>\n",
       "      <th>きょう</th>\n",
       "      <th>くき</th>\n",
       "      <th>くち</th>\n",
       "      <th>げ</th>\n",
       "      <th>こく</th>\n",
       "      <th>これ</th>\n",
       "      <th>ご</th>\n",
       "      <th>さ</th>\n",
       "      <th>さんぜん</th>\n",
       "      <th>ざし</th>\n",
       "      <th>し</th>\n",
       "      <th>しかして</th>\n",
       "      <th>しく</th>\n",
       "      <th>しゃ</th>\n",
       "      <th>しよ</th>\n",
       "      <th>すけ</th>\n",
       "      <th>する</th>\n",
       "      <th>せ</th>\n",
       "      <th>...</th>\n",
       "      <th>蹟</th>\n",
       "      <th>躍如</th>\n",
       "      <th>身辺</th>\n",
       "      <th>軋轢</th>\n",
       "      <th>軍</th>\n",
       "      <th>軟体動物</th>\n",
       "      <th>近世</th>\n",
       "      <th>迫っ</th>\n",
       "      <th>逃避</th>\n",
       "      <th>造営</th>\n",
       "      <th>連歌</th>\n",
       "      <th>運動</th>\n",
       "      <th>道楽</th>\n",
       "      <th>違い</th>\n",
       "      <th>遠から</th>\n",
       "      <th>部下</th>\n",
       "      <th>重臣</th>\n",
       "      <th>金閣寺</th>\n",
       "      <th>銀</th>\n",
       "      <th>銀閣</th>\n",
       "      <th>鎮圧</th>\n",
       "      <th>鐘</th>\n",
       "      <th>鑒</th>\n",
       "      <th>開</th>\n",
       "      <th>間</th>\n",
       "      <th>院</th>\n",
       "      <th>陰謀</th>\n",
       "      <th>雑</th>\n",
       "      <th>雑事</th>\n",
       "      <th>露骨</th>\n",
       "      <th>非常</th>\n",
       "      <th>面目</th>\n",
       "      <th>頂山</th>\n",
       "      <th>頭</th>\n",
       "      <th>頻発</th>\n",
       "      <th>願っ</th>\n",
       "      <th>風流</th>\n",
       "      <th>飢饉</th>\n",
       "      <th>驕奢</th>\n",
       "      <th>驚かす</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     (  )  )、  )。  )」(『  あたら  あつ  あまつさえ  ある  ...  面目  頂山  頭  頻発  願っ  風流  飢饉  驕奢  驚かす\n",
       "421  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "124  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "517  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "88   0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "245  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   1   0   0    0\n",
       "530  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "371  0  0   0   0     0    0   0      0   0  ...   0   0  0   0   0   0   0   0    0\n",
       "\n",
       "[7 rows x 434 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_token = tokenizer_janome.transform(sentence)\n",
    "\n",
    "onehot = OneHotEncoder_()\n",
    "onehot_vector = onehot.fit_transform(sample_token) # 形態素後の形式で渡す\n",
    "category = onehot.category() # 学習されたボキャブラリー\n",
    "\n",
    "df = pd.DataFrame(onehot_vector, columns=category).astype(int)\n",
    "df.sample(7) # スパース表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFGG-X9pMzmq",
    "outputId": "86708202-afcc-45af-e1a1-9cc32a3babda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['菊池'] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  vocab_text = onehot.inverse_transform(onehot_vector[i])\n",
    "  print(vocab_text, onehot_vector[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac799X3-Qw4b"
   },
   "source": [
    "形態素解析後の形式で学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7T38y0LN6bq"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec_()\n",
    "model.fit(sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fs6nO171Oh04",
    "outputId": "56b93be7-6c28-4aaf-b239-d8a210bac926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['金閣寺'] [ 1.0754883e-03  9.2043006e-04 -1.2501357e-03 -3.8391345e-03\n",
      "  2.5577752e-03  2.6046038e-03 -1.5338639e-03  3.3253478e-03\n",
      " -2.0590764e-03 -3.1306886e-03  1.6823123e-03  3.7537853e-03\n",
      " -1.9792411e-05 -2.3890934e-03  2.3350338e-05  1.1835764e-03\n",
      " -1.0267056e-03  4.2521133e-04  2.2842817e-03  2.6426243e-03\n",
      " -6.9568318e-04  1.4774076e-03 -3.0521111e-04 -2.0577062e-03\n",
      "  5.8990123e-04 -1.9868887e-03 -1.2759594e-03  3.1393233e-03\n",
      "  1.2983207e-03  3.4932201e-03  1.6512668e-03  1.8412912e-03\n",
      "  1.5560047e-04 -7.2002725e-04 -1.1728181e-03 -7.8719348e-04\n",
      " -1.1664472e-03  9.2579715e-04  1.8489970e-03  1.3267810e-03\n",
      " -2.3393761e-03  3.0516861e-03  1.4185682e-03  3.0599311e-03\n",
      "  3.0171128e-03  3.2746196e-03 -2.3217383e-03 -1.7931553e-03\n",
      " -8.8429090e-04 -1.3011908e-03 -2.8906981e-03 -1.1602493e-03\n",
      "  8.8499300e-04  2.4915114e-03  3.1894329e-04 -3.1350285e-03\n",
      "  2.5707338e-04  1.4599069e-03 -2.5173549e-03  2.0160899e-03\n",
      "  1.1310075e-04  3.5170903e-03  2.6471636e-03  3.2626239e-03\n",
      " -1.9601818e-04  1.7179155e-03 -3.8410346e-03 -3.6039553e-03\n",
      "  2.2992771e-03  2.9478443e-03  1.2034137e-03 -6.0683093e-04\n",
      " -1.2140548e-04 -1.5775610e-03 -1.6242869e-03 -2.6733747e-03\n",
      " -3.0255944e-03  1.3264023e-04 -3.8491718e-03 -1.7431066e-03\n",
      " -9.1457361e-04  3.3823554e-03  2.2694680e-03 -1.9908980e-03\n",
      "  2.7999904e-03  2.7349961e-03  1.5156417e-03 -3.2853414e-03\n",
      "  2.3818084e-03 -3.0375971e-03  3.1036797e-03 -1.5834715e-03\n",
      " -2.0990388e-03  2.6438329e-03 -1.6480745e-03 -6.8724810e-05\n",
      " -6.2960450e-04 -1.5564713e-03  3.8221644e-03  2.3620273e-03\n",
      " -1.6176957e-03  1.8168108e-03 -2.8885349e-03  8.3828240e-04\n",
      "  2.2665290e-03 -3.4564722e-03 -2.2026100e-03 -1.1482829e-03\n",
      "  2.8066533e-03 -1.7106572e-04  8.7473617e-04 -2.1245363e-03\n",
      " -2.2218677e-03 -8.0605719e-04 -4.5558656e-04 -1.7469587e-03\n",
      " -6.0388353e-05  1.1458838e-03 -2.6067505e-03 -2.1989082e-03\n",
      "  2.6483426e-03 -2.5251377e-03  3.3532607e-03  5.9759064e-04\n",
      "  1.3013552e-03  3.8419124e-03 -3.2491600e-03  1.6291603e-03]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "from vector\n",
      "[('金閣寺', 1.0), ('続い', 0.2766083776950836), ('千', 0.26868921518325806), ('政治', 0.2614019215106964)]\n",
      "from word\n",
      "[('続い', 0.2766083776950836), ('千', 0.26868921518325806), ('政治', 0.2614019215106964), ('とっ', 0.25815126299858093)]\n"
     ]
    }
   ],
   "source": [
    "word, word_vector = model.transform_word(\"金閣寺\") # 金閣寺ベクトル\n",
    "print(word, word_vector)\n",
    "\n",
    "print(\"-\"*100)\n",
    "similar_word = model.similar_by_vector(word_vector, topn=4) # コサイン類似度によるベクトルの取得\n",
    "print(\"from vector\")\n",
    "print(similar_word)\n",
    "\n",
    "similar_vector = model.similar_by_word(word[0], topn=4)\n",
    "print(\"from word\")\n",
    "print(similar_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mi9bJk2ZRTy_"
   },
   "source": [
    "ベクトルにノイズを加えることで疑似的なベクトルを作成します。  \n",
    "`scale_rate`でノイズを調整します。大きいほど対照的な意味を持つベクトルになります。  \n",
    "変換前とノイズ加算後でコサイン類似度を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MY10FwNMOvl6",
    "outputId": "9790bfa4-4179-4b56-bba8-c526bffdd143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similar: [[0.18476174]]\n",
      "restored_word1: [('金閣寺', 1.0)]\n",
      "restored_word1: [('あんた', 0.2086985558271408)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.92191211e-03,  5.78359539e-03,  5.77838720e-03, -1.75193385e-02,\n",
       "        1.24324095e-03, -3.32261243e-03,  1.17838227e-02,  1.26928037e-02,\n",
       "       -1.67301215e-02,  8.68672577e-03, -1.76915833e-02,  2.86695810e-02,\n",
       "        2.39182115e-02, -1.70055207e-02, -2.15745242e-02, -1.04453210e-02,\n",
       "        2.92566979e-03,  3.77615859e-03, -1.57802905e-02,  1.39539016e-02,\n",
       "        5.27500760e-04,  3.65108085e-02, -8.34531675e-04, -2.09375746e-03,\n",
       "       -8.21993485e-03, -9.91186648e-03, -1.88008996e-02,  2.21835306e-03,\n",
       "       -1.09106415e-02,  1.34938319e-02, -1.88658138e-02,  2.91904217e-02,\n",
       "       -2.09003977e-02, -8.42359297e-03,  1.72978645e-02, -2.46340537e-02,\n",
       "        1.84863269e-03,  4.18552036e-03, -2.90923337e-02,  2.43233506e-03,\n",
       "        1.98833394e-02, -5.99311256e-03, -2.55947319e-02,  5.56797339e-03,\n",
       "        7.89416372e-03,  1.40474613e-02, -6.25111248e-03, -2.04281048e-02,\n",
       "        2.58470603e-03,  1.79687601e-02,  7.24835646e-03, -1.24577331e-03,\n",
       "        2.30137355e-03,  7.80585844e-03, -1.11604795e-02, -2.46875025e-02,\n",
       "        7.63554257e-03, -9.52923322e-03, -2.45030365e-02,  2.67934765e-02,\n",
       "       -2.07114875e-02,  1.29188770e-02, -4.32833254e-03, -8.32129264e-03,\n",
       "        4.54657770e-03,  8.75081618e-03, -2.97191280e-03,  1.62561427e-03,\n",
       "       -5.28424699e-03,  5.95037934e-03,  9.89992764e-03,  1.38739585e-03,\n",
       "       -6.07411752e-03, -2.79902571e-02, -3.88182046e-03, -5.39564732e-03,\n",
       "       -2.16089572e-02, -1.52455647e-02,  1.55177717e-02, -1.44635353e-02,\n",
       "        2.32159327e-02, -2.29054434e-03, -1.43556746e-02,  1.47316764e-03,\n",
       "        3.40524011e-03,  1.54709332e-02,  2.67887020e-02, -5.96496437e-03,\n",
       "        1.86462744e-02,  1.97787216e-02,  6.04579597e-03, -3.56404982e-02,\n",
       "        6.32839571e-03,  1.06192720e-02, -1.86683245e-02,  1.34542773e-02,\n",
       "       -1.31499837e-02,  1.44125680e-02,  5.40611344e-05,  1.86971127e-02,\n",
       "       -9.84019265e-03, -1.07446490e-02, -9.53342167e-03, -3.91464069e-02,\n",
       "        6.98646462e-03, -8.84050292e-03,  6.58871791e-03,  5.34898403e-03,\n",
       "       -3.75109624e-03,  1.02758633e-03, -1.65144958e-02,  2.62738366e-02,\n",
       "        5.42797792e-03, -7.28624847e-03, -1.17563988e-02, -8.14041900e-03,\n",
       "       -1.05774860e-02, -8.29945895e-03,  2.79208173e-03,  3.19547303e-03,\n",
       "        1.18753486e-02,  1.76844585e-02,  1.29706067e-02,  8.65725207e-03,\n",
       "        9.10970830e-03, -2.36500610e-02, -1.33305142e-02,  7.51410422e-03])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.augment_by_normal_noise(word[0], scale_rate=7.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "uoEwDrxlO9bY",
    "outputId": "4a6ed08b-d613-44cc-8b0c-51d33365a521"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>菊池</th>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>-0.001510</td>\n",
       "      <td>0.002526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>寛</th>\n",
       "      <td>-0.003826</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>-0.001685</td>\n",
       "      <td>-0.003392</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.002306</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>-0.001352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>応仁</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>-0.003466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>乱</th>\n",
       "      <td>0.000966</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.002380</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>応仁</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>-0.003466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2  ...         7         8         9\n",
       "菊池 -0.000114 -0.000826  0.001668  ... -0.003601 -0.001510  0.002526\n",
       "寛  -0.003826 -0.001787  0.003844  ... -0.002306  0.001273 -0.001352\n",
       "応仁  0.000744  0.002804 -0.002049  ... -0.001284  0.001515 -0.003466\n",
       "乱   0.000966 -0.003771  0.000952  ...  0.002086  0.002538 -0.001024\n",
       "応仁  0.000744  0.002804 -0.002049  ... -0.001284  0.001515 -0.003466\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_all, names = [], []\n",
    "for token in sample_token[0][:10]:\n",
    "  name, vec = model.transform_word(token)\n",
    "  vec_all.append(vec)\n",
    "  names.append(name[0])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(vec_all, index=names)\n",
    "df.iloc[:5, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVoSxga0Ttzh"
   },
   "source": [
    "### 4. `SeqTransformToVector.py`の理解\n",
    "形態素解析のトークンから文章単位でベクトル化を行います。  \n",
    "つまり、ある文章$j$を一つのベクトルで表すことができます。$j$番目のベクトルはトークンを複合した形になります.  \n",
    "+ **Onehot**を合計する + **TF-IDF**\n",
    "+ **doc2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "jNK-c3CbVDF0"
   },
   "outputs": [],
   "source": [
    "from SeqTransformToVector import CountVectorizer_, TfidfVectorizer_, Doc2Vec_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "bKlhYnrFSBri",
    "outputId": "6995e788-7f40-40f4-8fed-565789f7c20d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document1</th>\n",
       "      <th>document2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>菊池</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>寛</th>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>応仁</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>乱</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>天下</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document1  document2\n",
       "sentence                      \n",
       "菊池               18         16\n",
       "寛                18         14\n",
       "応仁                0          1\n",
       "乱                 0          1\n",
       "天下                0          1"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer_()\n",
    "vec = count.fit_transform(sample_token)\n",
    "col = count.vocabulary()\n",
    "df = pd.DataFrame(vec).T\n",
    "df.columns = [\"document1\", \"document2\"]\n",
    "df[\"sentence\"] = col \n",
    "df.set_index([\"sentence\"])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8G1lY6iYWou"
   },
   "source": [
    "単語の出現数、レア度を考慮。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "DVgK3oQ4WED1",
    "outputId": "60048ce1-7524-4b0e-dd4d-8774119be0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document1</th>\n",
       "      <th>document2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>菊池</th>\n",
       "      <td>0.416429</td>\n",
       "      <td>0.478846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>寛</th>\n",
       "      <td>0.416429</td>\n",
       "      <td>0.418990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>応仁</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>乱</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>天下</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          document1  document2\n",
       "sentence                      \n",
       "菊池         0.416429   0.478846\n",
       "寛          0.416429   0.418990\n",
       "応仁         0.000000   0.042063\n",
       "乱          0.000000   0.042063\n",
       "天下         0.000000   0.042063"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer_()\n",
    "vec = tfidf.fit_transform(sample_token)\n",
    "col = tfidf.vocabulary()\n",
    "df = pd.DataFrame(vec).T\n",
    "df.columns = [\"document1\", \"document2\"]\n",
    "df[\"sentence\"] = col \n",
    "df.set_index([\"sentence\"])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-MBEGWIYKXu",
    "outputId": "8b15c403-e57f-4757-b28f-629d71097683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "collected 434 word types and 4 unique tags from a corpus of 2 examples and 690 words\n",
      "Loading a fresh vocabulary\n",
      "effective_min_count=1 retains 434 unique words (100% of original 434, drops 0)\n",
      "effective_min_count=1 leaves 690 word corpus (100% of original 690, drops 0)\n",
      "deleting the raw counts dictionary of 434 items\n",
      "sample=0.001 downsamples 79 most-common words\n",
      "downsampling leaves estimated 533 word corpus (77.4% of prior 690)\n",
      "estimated required memory for 434 words and 128 dimensions: 663864 bytes\n",
      "resetting layer weights\n",
      "training model with 3 workers on 434 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 1 : training on 690 raw words (540 effective words) took 0.0s, 67658 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 2 : training on 690 raw words (549 effective words) took 0.0s, 96826 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 3 : training on 690 raw words (544 effective words) took 0.0s, 59029 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 4 : training on 690 raw words (530 effective words) took 0.0s, 57419 effective words/s\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 5 : training on 690 raw words (534 effective words) took 0.0s, 71561 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_count': 1, 'seed': 888, 'vector_size': 128, 'window': 5, 'worker': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training on a 3450 raw words (2697 effective words) took 0.1s, 37519 effective words/s\n",
      "under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/m,d128,n5,w5,s0.001,t3)\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec_()\n",
    "model.fit(sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBPuLYBHYvsw",
    "outputId": "a7e5a502-8ee3-4b51-c92d-2aa2fa6bce14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01616318, -0.01587567, -0.01056288, -0.00607437,  0.0015838 ,\n",
       "       -0.01106674, -0.00290009, -0.01077205,  0.00440427,  0.00047479,\n",
       "        0.00277381,  0.00431481, -0.01635395, -0.00178392, -0.00633888,\n",
       "       -0.00143261,  0.00255995,  0.00692431,  0.0093954 ,  0.00625542,\n",
       "        0.01754118, -0.0032147 , -0.00563844, -0.00636444,  0.01873167,\n",
       "        0.00027449,  0.01388272, -0.00427669,  0.00539464,  0.00064231,\n",
       "        0.01051454,  0.00532097,  0.00928723,  0.00198583, -0.01071727,\n",
       "       -0.00450149, -0.01027502, -0.00110093,  0.00672815, -0.00882165,\n",
       "       -0.0030893 ,  0.00214431,  0.00893028,  0.0120031 ,  0.0017827 ,\n",
       "       -0.00627814, -0.00925335, -0.01102601,  0.02308089, -0.00121964,\n",
       "        0.00712351,  0.00195475, -0.00689315,  0.01161343, -0.00066682,\n",
       "       -0.00299436, -0.00872589,  0.00647259, -0.0081091 , -0.00169248,\n",
       "       -0.00283338, -0.00687849,  0.01511728, -0.00911613,  0.00013759,\n",
       "       -0.00020807, -0.00795727, -0.00430141, -0.01661504, -0.00466011,\n",
       "       -0.01138704,  0.00254313, -0.01265598, -0.00614352,  0.00185723,\n",
       "        0.00566667, -0.00669452, -0.00416093, -0.00701025,  0.00073488,\n",
       "        0.00465812, -0.00451055,  0.00360964, -0.0141317 , -0.00135701,\n",
       "        0.0105135 , -0.01962598,  0.00095895, -0.00662656,  0.00425973,\n",
       "        0.00260208, -0.00742876, -0.0078857 , -0.00311735,  0.00078879,\n",
       "        0.00736958,  0.01026349,  0.00378797, -0.01294246, -0.00713175,\n",
       "        0.00335871,  0.00777077,  0.00057066, -0.00515419, -0.00662914,\n",
       "       -0.00041625, -0.02114577,  0.01089056,  0.0039417 , -0.00736981,\n",
       "        0.0021262 , -0.00356361, -0.00928784, -0.00397041, -0.00770589,\n",
       "       -0.00305483,  0.01606847, -0.00652188,  0.01205316,  0.00095412,\n",
       "        0.0080165 , -0.00437163,  0.01024267, -0.00202248, -0.0002685 ,\n",
       "        0.00970223, -0.00534122, -0.00697808], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = model.transform_sequence(sample_token[0]) # 1文章ベクトル\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TcylzyDZJcL",
    "outputId": "31c955c2-38c1-4e63-d748-2828ebc17d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.8880509e-03, -1.5155841e-03,  9.2712184e-04,  2.6573094e-03,\n",
       "        1.1504769e-03, -1.4343668e-03, -2.7596722e-03, -3.9052893e-03,\n",
       "        3.4564515e-03,  6.6106237e-04, -2.0718444e-03, -3.4069410e-03,\n",
       "       -2.7888454e-03,  3.0205001e-03, -2.6671134e-03, -2.8944644e-03,\n",
       "       -3.2238625e-03,  1.5689279e-03, -2.3122204e-03, -4.6651781e-04,\n",
       "        4.1614496e-04, -1.6039235e-03, -2.1761868e-03, -1.6252839e-03,\n",
       "       -7.5196737e-04, -1.2084139e-03,  3.0172302e-03,  2.6982040e-03,\n",
       "       -1.4516055e-03, -3.0113708e-03,  1.5549440e-04,  3.7610501e-03,\n",
       "        2.4293624e-03, -1.5815161e-03,  1.0646931e-03, -3.8788784e-03,\n",
       "       -2.1455646e-03, -5.7026889e-04,  2.0165250e-03, -3.2227810e-03,\n",
       "        1.4413348e-03,  3.2083353e-03, -2.1225270e-03,  5.7905272e-04,\n",
       "       -1.8472741e-03,  2.5094002e-03,  2.4078286e-03,  3.3747131e-06,\n",
       "       -1.9170087e-03,  1.7497824e-04,  7.3612534e-04,  3.1240566e-03,\n",
       "        2.2382941e-03, -6.8576954e-04, -3.3407023e-03, -1.1063823e-03,\n",
       "       -2.6139678e-03,  3.0194810e-03,  3.4793655e-03,  2.8819616e-03,\n",
       "        3.4048387e-03, -1.8263244e-03,  1.6934024e-03, -1.8210905e-03,\n",
       "        3.7973942e-03,  3.6291450e-03,  6.6078000e-04,  3.7864421e-03,\n",
       "       -6.6301954e-04, -4.2857134e-04,  2.0958702e-03,  2.2243925e-04,\n",
       "       -1.2230814e-03,  2.4304325e-03, -7.2731735e-04,  2.0483963e-04,\n",
       "        8.1101352e-05,  1.6360014e-04, -2.9081260e-03,  5.5918226e-04,\n",
       "       -1.0196284e-03, -3.2758742e-04, -7.9887256e-04, -3.1354185e-03,\n",
       "        7.3630922e-04,  3.1146412e-03,  2.2350976e-03, -1.2429802e-03,\n",
       "        2.6079796e-03,  2.1175265e-03,  3.1266850e-03,  2.6495303e-03,\n",
       "        1.4701788e-03,  3.3970661e-03,  2.8439984e-03,  1.4594325e-03,\n",
       "        2.5455882e-03, -2.6843823e-03,  2.0575272e-03, -1.0543893e-03,\n",
       "        1.9163334e-04,  3.8312506e-03, -2.0080891e-03,  1.5513885e-03,\n",
       "       -1.5346693e-03,  5.3841539e-04,  1.6712251e-03, -3.6029704e-03,\n",
       "        3.5831167e-03,  1.8433791e-03, -2.8511288e-03, -1.0432740e-03,\n",
       "       -2.1780204e-04, -7.3699321e-04,  2.0522289e-03, -8.2962069e-04,\n",
       "        1.5214294e-03, -7.2966045e-04,  4.5943545e-04,  2.2389381e-03,\n",
       "        3.4269013e-03, -5.4503343e-04,  1.2572929e-03,  2.7831751e-03,\n",
       "        2.9433558e-03,  2.5268202e-04, -2.2495743e-03, -1.2151205e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"私は機械学習が大好きです\"\n",
    "dummy = model.predict(text) # 未知の文章への予測補完の例\n",
    "dummy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTRjqkFZufFcvh9CI6yyJ8",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1HQp6K87CmgGzrjCYkVMzJbzeuoUWH7Cz",
   "name": "sample-coda-NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
